import streamlit as st
import cv2
import face_recognition
import numpy as np
import pandas as pd
import requests
import os
import time
from datetime import datetime

# ================= 1. C·∫§U H√åNH K·∫æT N·ªêI =================
ESP32_CAM_IP = "172.20.10.14"       
ESP32_CONTROL_IP = "172.20.10.2"    

URL_STREAM = f"http://{ESP32_CAM_IP}:81/stream"
URL_CHECK_PIR = f"http://{ESP32_CONTROL_IP}/check_pir"
URL_OPEN = f"http://{ESP32_CONTROL_IP}/open"
URL_FAIL = f"http://{ESP32_CONTROL_IP}/fail"

DATASET_DIR = "dataset"
TOLERANCE = 0.50 

if not os.path.exists(DATASET_DIR):
    os.makedirs(DATASET_DIR)

# ================= 2. QU·∫¢N L√ù SESSION STATE =================
if 'system_state' not in st.session_state:
    st.session_state.system_state = "IDLE" 
if 'temp_reg_name' not in st.session_state:
    st.session_state.temp_reg_name = ""
if 'reg_step' not in st.session_state:
    st.session_state.reg_step = 0
if 'attendance_log' not in st.session_state:
    st.session_state.attendance_log = pd.DataFrame(columns=["Th·ªùi gian", "H·ªç t√™n", "Tr·∫°ng th√°i"])

# ================= 3. H√ÄM X·ª¨ L√ù =================

@st.cache_resource
def load_database():
    known_encodings = []
    known_names = []
    if os.path.exists(DATASET_DIR):
        for file in os.listdir(DATASET_DIR):
            if file.endswith((".jpg", ".png", ".jpeg")):
                path = os.path.join(DATASET_DIR, file)
                try:
                    image = face_recognition.load_image_file(path)
                    encodings = face_recognition.face_encodings(image)
                    if len(encodings) > 0:
                        known_encodings.append(encodings[0])
                        name = os.path.splitext(file)[0].split('_')[0]
                        known_names.append(name)
                except Exception: pass
    return known_encodings, known_names

def reload_data():
    st.cache_resource.clear()
    return load_database()

def send_to_screen_success(name):
    try:
        now_str = datetime.now().strftime("%H:%M")
        requests.get(URL_OPEN, params={"name":f"{name}  {now_str}"}, timeout=2)
    except: pass

def send_to_screen_fail():
    try: requests.get(URL_FAIL, timeout=2)
    except: pass

# --- H√ÄM QUAN TR·ªåNG: STREAM V√Ä T·ª∞ ƒê·ªòNG CH·ª§P ---
def auto_capture_stream(cam_placeholder, status_placeholder, step, name):
    """
    H√†m n√†y stream camera li√™n t·ª•c. 
    T·ªëi ∆∞u h√≥a: Resize ·∫£nh nh·ªè ƒë·ªÉ detect nhanh -> Video m∆∞·ª£t.
    """
    cap = cv2.VideoCapture(URL_STREAM)
    if not cap.isOpened(): 
        st.error("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi Camera ESP32!")
        return False, None
    
    msg = {1: "Nh√¨n TH·∫≤NG", 2: "Quay nh·∫π TR√ÅI", 3: "Quay nh·∫π PH·∫¢I"}.get(step, "")
    
    stable_count = 0
    REQUIRED_STABLE = 10 # S·ªë frame c·∫ßn gi·ªØ y√™n (kho·∫£ng 1-2 gi√¢y)
    captured_frame = None
    
    # N√∫t h·ªßy (ƒë·∫∑t b√™n ngo√†i loop b·∫±ng trick container, nh∆∞ng ·ªü ƒë√¢y ta d√πng logic loop)
    # Streamlit h∆°i kh√≥ b·∫Øt s·ª± ki·ªán n√∫t trong v√≤ng l·∫∑p while, n√™n ta d√πng Auto-Capture l√† ch√≠nh.
    
    while True:
        ret, frame = cap.read()
        if not ret: 
            break
        
        # 1. Resize si√™u nh·ªè ƒë·ªÉ nh·∫≠n di·ªán cho nhanh (TƒÉng FPS)
        # Gi·∫£m xu·ªëng 1/4 k√≠ch th∆∞·ªõc ƒë·ªÉ AI x·ª≠ l√Ω m∆∞·ª£t
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
        # 2. Detect khu√¥n m·∫∑t
        faces = face_recognition.face_locations(rgb_small)
        
        # 3. V·∫Ω giao di·ªán l√™n ·∫£nh g·ªëc (·∫¢nh to)
        display_frame = frame.copy()
        h, w, _ = display_frame.shape
        
        if len(faces) == 1:
            stable_count += 1
            # V·∫Ω thanh ti·∫øn tr√¨nh m√†u xanh
            progress_width = int((stable_count / REQUIRED_STABLE) * w)
            cv2.rectangle(display_frame, (0, h-20), (progress_width, h), (0, 255, 0), -1)
            cv2.putText(display_frame, f"GIU YEN... {int((stable_count/REQUIRED_STABLE)*100)}%", (20, h-40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # N·∫øu gi·ªØ y√™n ƒë·ªß l√¢u -> Ch·ª•p
            if stable_count >= REQUIRED_STABLE:
                captured_frame = frame # L∆∞u frame g·ªëc s·∫Øc n√©t
                break
        else:
            stable_count = 0 # Reset n·∫øu m·∫•t m·∫∑t ho·∫∑c quay qu√° nhanh
            color = (0, 255, 255) # V√†ng
            if len(faces) == 0: 
                txt = "KHONG THAY MAT"
                color = (0, 0, 255) # ƒê·ªè
            elif len(faces) > 1: 
                txt = "CHI 1 NGUOI THOI"
                color = (0, 0, 255)
            else:
                txt = msg
                
            cv2.putText(display_frame, f"B{step}: {msg}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            cv2.putText(display_frame, txt, (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        # 4. ƒê·∫©y ·∫£nh l√™n giao di·ªán ngay l·∫≠p t·ª©c
        # D√πng use_container_width=True ƒë·ªÉ ·∫£nh to r√µ
        cam_placeholder.image(cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
        
        # Sleep c·ª±c ng·∫Øn ƒë·ªÉ nh∆∞·ªùng CPU
        time.sleep(0.01)
        
    cap.release()
    return True, captured_frame

# H√†m Qu√©t m·∫∑t khi ch·∫•m c√¥ng (C≈©ng t·ªëi ∆∞u hi·ªÉn th·ªã)
def scan_face_slowly(cam_ph, status_ph, encodings, names):
    cap = cv2.VideoCapture(URL_STREAM)
    if not cap.isOpened(): return None
    
    found = None
    max_attempts = 3
    
    for i in range(max_attempts):
        # ƒê·∫øm ng∆∞·ª£c 3s (V·ª´a ƒë·∫øm v·ª´a stream ƒë·ªÉ kh√¥ng b·ªã ƒë·ª©ng h√¨nh)
        start_time = time.time()
        while time.time() - start_time < 2: # ƒê·∫øm 2 gi√¢y
            ret, frame = cap.read()
            if ret:
                cv2.putText(frame, f"QUET LAN {i+1}...", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)
                countdown = 2 - int(time.time() - start_time)
                cv2.putText(frame, str(countdown), (300, 240), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,255), 5)
                cam_ph.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
            time.sleep(0.05)
            
        # Ch·ª•p th·∫≠t
        ret, frame = cap.read()
        if not ret: continue
        
        # Nh·∫≠n di·ªán (Resize nh·ªè cho nhanh)
        small = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)
        rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)
        locs = face_recognition.face_locations(rgb)
        encs = face_recognition.face_encodings(rgb, locs)
        
        if encs:
            matches = face_recognition.compare_faces(encodings, encs[0], tolerance=TOLERANCE)
            dists = face_recognition.face_distance(encodings, encs[0])
            best = np.argmin(dists)
            if matches[best]:
                found = names[best]
                break
        
        if not found:
            status_ph.warning(f"‚ö†Ô∏è L·∫ßn {i+1}: Kh√¥ng kh·ªõp!")
            
    cap.release()
    return found

# ================= 4. GIAO DI·ªÜN CH√çNH =================
st.set_page_config(page_title="H·ªá Th·ªëng Ch·∫•m C√¥ng AI", layout="wide")
st.title("üõ°Ô∏è H·ªá Th·ªëng Ch·∫•m C√¥ng & ƒêi·ªÉm Danh")

# Load d·ªØ li·ªáu
encodings, names = load_database()

# Layout ch√≠nh: 2 C·ªôt (Camera - L·ªãch s·ª≠)
col_L, col_R = st.columns([0.65, 0.35])

with col_L:
    st.subheader("üî¥ Camera Monitor")
    cam_ph = st.empty() # Placeholder cho Camera
    status_ph = st.empty() # Placeholder cho th√¥ng b√°o
    
    # Khu v·ª±c ƒëi·ªÅu khi·ªÉn (·∫©n hi·ªán linh ho·∫°t)
    control_container = st.container()

with col_R:
    st.subheader("üìã L·ªãch s·ª≠ ƒêi·ªÉm danh")
    # N√∫t x√≥a log
    if st.button("üóëÔ∏è X√≥a L·ªãch S·ª≠"):
        st.session_state.attendance_log = pd.DataFrame(columns=["Th·ªùi gian", "H·ªç t√™n", "Tr·∫°ng th√°i"])
        st.rerun()
        
    # Hi·ªÉn th·ªã b·∫£ng log (T·ª± ƒë·ªông c·∫≠p nh·∫≠t)
    st.dataframe(
        st.session_state.attendance_log, 
        use_container_width=True, 
        hide_index=True,
        height=400
    )

# Sidebar ƒëi·ªÅu khi·ªÉn
with st.sidebar:
    st.header("‚öôÔ∏è ƒêi·ªÅu khi·ªÉn")
    if st.button("üîÑ RESET V·ªÄ M·∫∂C ƒê·ªäNH"):
        st.session_state.system_state = "IDLE"
        st.rerun()
    st.info(f"ƒê√£ h·ªçc: {len(names)} khu√¥n m·∫∑t")

# --- STATE MACHINE ---

# 1. TR·∫†NG TH√ÅI IDLE (CH·ªú)
if st.session_state.system_state == "IDLE":
    status_ph.info("üí§ ƒêang ch·ªù c·∫£m bi·∫øn chuy·ªÉn ƒë·ªông...")
    cam_ph.image("https://media.tenor.com/On7kvXhzml4AAAAj/loading-gif.gif", width=150)
    
    # Check PIR
    try:
        r = requests.get(URL_CHECK_PIR, timeout=0.5)
        if r.text.strip() == "1":
            st.session_state.system_state = "SCANNING"
            st.rerun()
    except: time.sleep(1)
    time.sleep(1)
    st.rerun()

# 2. TR·∫†NG TH√ÅI QU√âT (SCANNING)
elif st.session_state.system_state == "SCANNING":
    name = scan_face_slowly(cam_ph, status_ph, encodings, names)
    
    if name:
        status_ph.success(f"‚úÖ X√°c nh·∫≠n: {name}")
        send_to_screen_success(name)
        
        # Ghi Log
        row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": name, "Tr·∫°ng th√°i": "Th√†nh c√¥ng"}
        st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)
        
        time.sleep(5)
        st.session_state.system_state = "IDLE"
        st.rerun()
    else:
        send_to_screen_fail()
        # Ghi Log th·∫•t b·∫°i
        row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": "Unknown", "Tr·∫°ng th√°i": "Th·∫•t b·∫°i"}
        st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)
        
        st.session_state.system_state = "FAIL_OPT"
        st.rerun()

# 3. TR·∫†NG TH√ÅI H·ªéI (FAIL OPTION)
elif st.session_state.system_state == "FAIL_OPT":
    status_ph.error("‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c!")
    cam_ph.info("B·∫°n c√≥ mu·ªën ƒëƒÉng k√Ω khu√¥n m·∫∑t m·ªõi kh√¥ng?")
    
    with control_container:
        c1, c2 = st.columns(2)
        if c1.button("üìù ƒêƒÉng k√Ω ngay"):
            st.session_state.system_state = "REGISTER"
            st.session_state.reg_step = 1
            st.rerun()
        if c2.button("‚û°Ô∏è B·ªè qua"):
            st.session_state.system_state = "IDLE"
            st.rerun()

# 4. TR·∫†NG TH√ÅI ƒêƒÇNG K√ù (REGISTER)
elif st.session_state.system_state == "REGISTER":
    if not st.session_state.temp_reg_name:
        cam_ph.empty()
        status_ph.info("Nh·∫≠p t√™n nh√¢n vi√™n m·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu:")
        with control_container:
            val = st.text_input("H·ªç v√† T√™n (Vi·∫øt li·ªÅn, kh√¥ng d·∫•u):")
            if st.button("üì∏ B·∫Øt ƒë·∫ßu ch·ª•p") and val:
                st.session_state.temp_reg_name = val
                st.rerun()
    else:
        # V√†o quy tr√¨nh ch·ª•p Auto Stream
        name = st.session_state.temp_reg_name
        step = st.session_state.reg_step
        
        # G·ªçi h√†m stream li√™n t·ª•c
        ok, frame = auto_capture_stream(cam_ph, status_ph, step, name)
        
        if ok and frame is not None:
            suffix = ["front", "left", "right"][step-1]
            cv2.imwrite(os.path.join(DATASET_DIR, f"{name}_{suffix}.jpg"), frame)
            
            st.toast(f"‚úÖ ƒê√£ l∆∞u g√≥c {suffix}!", icon="üíæ")
            
            if step < 3:
                st.session_state.reg_step += 1
                st.rerun()
            else:
                reload_data()
                st.success("üéâ ƒêƒÉng k√Ω th√†nh c√¥ng! ƒêang t·∫£i l·∫°i d·ªØ li·ªáu...")
                
                # Ghi Log ƒëƒÉng k√Ω
                row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": name, "Tr·∫°ng th√°i": "ƒêƒÉng k√Ω m·ªõi"}
                st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)

                st.session_state.temp_reg_name = ""
                st.session_state.reg_step = 0
                st.session_state.system_state = "IDLE"
                time.sleep(3)
                st.rerun()