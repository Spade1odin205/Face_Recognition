import streamlit as st
import cv2
import numpy as np
import pandas as pd
import requests
import os
import time
from datetime import datetime
from insightface.app import FaceAnalysis

# ================= 1. C·∫§U H√åNH K·∫æT N·ªêI =================
ESP32_CAM_IP = "172.20.10.14"       
ESP32_CONTROL_IP = "172.20.10.2"    

URL_STREAM = f"http://{ESP32_CAM_IP}:81/stream"
URL_CHECK_PIR = f"http://{ESP32_CONTROL_IP}/check_pir"
URL_OPEN = f"http://{ESP32_CONTROL_IP}/open"
URL_FAIL = f"http://{ESP32_CONTROL_IP}/fail"

DATASET_DIR = "dataset"

# Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng (Cosine Similarity): > 0.5 l√† gi·ªëng, > 0.6 l√† r·∫•t gi·ªëng
SIMILARITY_THRESHOLD = 0.50 

if not os.path.exists(DATASET_DIR):
    os.makedirs(DATASET_DIR)

# ================= 2. QU·∫¢N L√ù SESSION STATE =================
if 'system_state' not in st.session_state:
    st.session_state.system_state = "IDLE" 
if 'temp_reg_name' not in st.session_state:
    st.session_state.temp_reg_name = ""
if 'reg_step' not in st.session_state:
    st.session_state.reg_step = 0
if 'attendance_log' not in st.session_state:
    st.session_state.attendance_log = pd.DataFrame(columns=["Th·ªùi gian", "H·ªç t√™n", "Tr·∫°ng th√°i"])
# Cooldown ƒë·ªÉ tr√°nh qu√©t li√™n t·ª•c khi PIR v·∫´n ƒëang HIGH
if 'cooldown_until' not in st.session_state:
    st.session_state.cooldown_until = 0.0

# ================= 3. KH·ªûI T·∫†O INSIGHTFACE =================
@st.cache_resource
def load_model():
    # S·ª≠ d·ª•ng model buffalo_s (ch·ª©a MobileFaceNet) si√™u nh·∫π cho CPU
    print("[INIT] Loading InsightFace Model...")
    app = FaceAnalysis(name='buffalo_s', providers=['CPUExecutionProvider'])
    app.prepare(ctx_id=0, det_size=(640, 640))
    return app

# H√†m t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Cosine
def compute_sim(feat1, feat2):
    return np.dot(feat1, feat2) / (np.linalg.norm(feat1) * np.linalg.norm(feat2))

@st.cache_resource
def load_database(_model):
    known_embeddings = []
    known_names = []
    print("[DATA] Loading Database...")
    if os.path.exists(DATASET_DIR):
        for file in os.listdir(DATASET_DIR):
            if file.endswith((".jpg", ".png", ".jpeg")):
                path = os.path.join(DATASET_DIR, file)
                try:
                    # InsightFace ƒë·ªçc ·∫£nh BGR (OpenCV m·∫∑c ƒë·ªãnh)
                    img = cv2.imread(path)
                    if img is None: continue
                    
                    faces = _model.get(img)
                    if len(faces) > 0:
                        # L·∫•y khu√¥n m·∫∑t l·ªõn nh·∫•t trong ·∫£nh
                        face = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0]) * (x.bbox[3]-x.bbox[1]))[-1]
                        known_embeddings.append(face.embedding)
                        name = os.path.splitext(file)[0].split('_')[0]
                        known_names.append(name)
                except Exception as e:
                    print(f"Error loading {file}: {e}")
    return known_embeddings, known_names

def reload_data(model):
    st.cache_resource.clear()
    return load_database(model)

# ================= 4. C√ÅC H√ÄM X·ª¨ L√ù LOGIC =================

def send_to_screen_success(name):
    try:
        now_str = datetime.now().strftime("%H:%M")
        requests.get(URL_OPEN, params={"name": f"{name}  {now_str}"}, timeout=2)
    except: pass

def send_to_screen_fail():
    try: requests.get(URL_FAIL, timeout=2)
    except: pass

def auto_capture_stream(cam_placeholder, status_placeholder, step, name, model):
    cap = cv2.VideoCapture(URL_STREAM)
    if not cap.isOpened(): 
        st.error("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi Camera ESP32!")
        return False, None

    try:
        # ƒê·ªãnh nghƒ©a h∆∞·ªõng d·∫´n cho t·ª´ng b∆∞·ªõc
        steps_info = {
            1: "Nhin thang vao Camera", 
            2: "Quay mat sang TRAI", 
            3: "Quay mat sang PHAI"
        }
        msg = steps_info.get(step, "")
        
        stable_count = 0
        REQUIRED_STABLE = 8  # Gi·∫£m xu·ªëng ch√∫t cho d·ªÖ ch·ª•p sau khi ƒë√£ ch·ªù
        captured_frame = None
        SCALE_FACTOR = 0.25
        frame_count = 0 
        SKIP_FRAMES = 3 
        last_faces = [] 
        
        # --- GIAI ƒêO·∫†N 1: ƒê·∫æM NG∆Ø·ª¢C (ƒê·ªÇ B·∫†N K·ªäP QUAY ƒê·∫¶U) ---
        # Th·ªùi gian ch·ªù: 3 gi√¢y cho b∆∞·ªõc 1, 4 gi√¢y cho b∆∞·ªõc 2,3 (ƒë·ªÉ k·ªãp xoay)
        wait_time = 3 if step == 1 else 4
        start_time = time.time()
        
        while time.time() - start_time < wait_time:
            ret, frame = cap.read()
            if not ret: break
            
            # Ch·ªâ hi·ªÉn th·ªã ƒë·∫øm ng∆∞·ª£c, kh√¥ng x·ª≠ l√Ω AI
            countdown = wait_time - int(time.time() - start_time)
            display_frame = frame.copy()
            
            # V·∫Ω m√†n h√¨nh t·ªëi ƒëi m·ªôt ch√∫t ƒë·ªÉ t·∫≠p trung
            overlay = display_frame.copy()
            cv2.rectangle(overlay, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.3, display_frame, 0.7, 0, display_frame)
            
            # In ch·ªØ to gi·ªØa m√†n h√¨nh
            text = f"BUOC {step}: {msg}"
            cv2.putText(display_frame, text, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            cv2.putText(display_frame, f"CHUAN BI... {countdown}", (150, 250), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4)
            
            cam_placeholder.image(cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
            time.sleep(0.05)

        # --- GIAI ƒêO·∫†N 2: B·∫ÆT ƒê·∫¶U QU√âT V√Ä CH·ª§P ---
        while True:
            ret, frame = cap.read()
            if not ret: break
            
            display_frame = frame.copy()
            h, w, _ = display_frame.shape
            frame_count += 1
            
            # Frame Skipping cho m∆∞·ª£t
            if frame_count % SKIP_FRAMES == 0:
                small_frame = cv2.resize(frame, (0, 0), fx=SCALE_FACTOR, fy=SCALE_FACTOR)
                last_faces = model.get(small_frame)
            
            # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n li√™n t·ª•c
            cv2.putText(display_frame, f"B{step}: {msg}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

            if len(last_faces) == 1:
                if frame_count % SKIP_FRAMES == 0:
                    stable_count += 1
                
                face = last_faces[0]
                box = (face.bbox / SCALE_FACTOR).astype(int)
                
                # V·∫Ω khung xanh
                cv2.rectangle(display_frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
                
                # Thanh ti·∫øn tr√¨nh
                progress_width = int((stable_count / REQUIRED_STABLE) * w)
                cv2.rectangle(display_frame, (0, h-20), (progress_width, h), (0, 255, 0), -1)
                cv2.putText(display_frame, f"GIU YEN... {int((stable_count/REQUIRED_STABLE)*100)}%", (20, h-40), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                
                if stable_count >= REQUIRED_STABLE:
                    captured_frame = frame
                    break
            else:
                if frame_count % SKIP_FRAMES == 0:
                    stable_count = 0
                
                status_text = "KHONG THAY MAT" if len(last_faces) == 0 else "CHI 1 NGUOI THOI"
                cv2.putText(display_frame, status_text, (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

            cam_placeholder.image(cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
            time.sleep(0.01)
            
        return True, captured_frame
    finally:
        cap.release()

# --- H√ÄM QU√âT CH·∫§M C√îNG (INSIGHTFACE) ---
def scan_face_slowly(cam_ph, status_ph, known_embeddings, known_names, model):
    cap = cv2.VideoCapture(URL_STREAM)
    if not cap.isOpened(): return None

    try:
        found_name = None
        max_attempts = 3
        
        for i in range(max_attempts):
            # ƒê·∫øm ng∆∞·ª£c v√† hi·ªÉn th·ªã stream
            start_time = time.time()
            while time.time() - start_time < 5:
                ret, frame = cap.read()
                if ret:
                    cv2.putText(frame, f"QUET LAN {i+1}...", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)
                    countdown = 5 - int(time.time() - start_time)
                    cv2.putText(frame, str(countdown), (300, 240), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,255), 5)
                    cam_ph.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
                time.sleep(0.05)
                
            # Ch·ª•p ·∫£nh ƒë·ªÉ x·ª≠ l√Ω
            ret, frame = cap.read()
            if not ret: continue
            
            # Nh·∫≠n di·ªán
            faces = model.get(frame)
            
            if len(faces) > 0:
                # L·∫•y m·∫∑t l·ªõn nh·∫•t
                face = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0]) * (x.bbox[3]-x.bbox[1]))[-1]
                
                # So s√°nh v·ªõi database (Cosine Similarity)
                max_score = 0
                best_idx = -1
                
                for idx, embed in enumerate(known_embeddings):
                    score = compute_sim(face.embedding, embed)
                    if score > max_score:
                        max_score = score
                        best_idx = idx
                
                # Ki·ªÉm tra ng∆∞·ª°ng
                if max_score > SIMILARITY_THRESHOLD:
                    found_name = known_names[best_idx]
                    break
            
            if not found_name:
                status_ph.warning(f"‚ö†Ô∏è L·∫ßn {i+1}: Kh√¥ng kh·ªõp!")
                
        return found_name
    finally:
        cap.release()

# ================= 5. GIAO DI·ªÜN CH√çNH =================
st.set_page_config(page_title="InsightFace Attendance", layout="wide")
st.title("üõ°Ô∏è H·ªá Th·ªëng Ch·∫•m C√¥ng (InsightFace MobileNet)")

# Load Model & Data
face_app = load_model()
encodings, names = load_database(face_app)

col_L, col_R = st.columns([0.65, 0.35])

with col_L:
    st.subheader("üî¥ Camera Monitor")
    cam_ph = st.empty()
    status_ph = st.empty()
    control_container = st.container()

with col_R:
    st.subheader("üìã L·ªãch s·ª≠ ƒêi·ªÉm danh")
    if st.button("üóëÔ∏è X√≥a L·ªãch S·ª≠"):
        st.session_state.attendance_log = pd.DataFrame(columns=["Th·ªùi gian", "H·ªç t√™n", "Tr·∫°ng th√°i"])
        st.rerun()
        
    st.dataframe(
        st.session_state.attendance_log, 
        use_container_width=True, 
        hide_index=True,
        height=400
    )

with st.sidebar:
    st.header("‚öôÔ∏è ƒêi·ªÅu khi·ªÉn")
    if st.button("üîÑ RESET"):
        st.session_state.system_state = "IDLE"
        st.rerun()
    st.info(f"ƒê√£ h·ªçc: {len(names)} khu√¥n m·∫∑t")

# --- STATE MACHINE ---

if st.session_state.system_state == "IDLE":
    status_ph.info("üí§ ƒêang ch·ªù c·∫£m bi·∫øn chuy·ªÉn ƒë·ªông...")
    cam_ph.image("https://media.tenor.com/On7kvXhzml4AAAAj/loading-gif.gif", width=150)

    # N·∫øu ƒëang trong cooldown th√¨ kh√¥ng g·ªçi PIR (tr√°nh k√≠ch qu√©t li√™n t·ª•c)
    if time.time() < st.session_state.cooldown_until:
        time.sleep(0.3)
        st.rerun()

    try:
        r = requests.get(URL_CHECK_PIR, timeout=0.5)
        if r.text.strip() == "1":
            st.session_state.system_state = "SCANNING"
            st.rerun()
    except: time.sleep(1)
    time.sleep(1)
    st.rerun()

elif st.session_state.system_state == "SCANNING":
    # Truy·ªÅn th√™m face_app model v√†o h√†m
    name = scan_face_slowly(cam_ph, status_ph, encodings, names, face_app)
    
    if name:
        status_ph.success(f"‚úÖ X√°c nh·∫≠n: {name}")
        send_to_screen_success(name)
        
        row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": name, "Tr·∫°ng th√°i": "Th√†nh c√¥ng"}
        st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)
        
        # Th·ªùi gian gi·ªØ tr·∫°ng th√°i th√†nh c√¥ng + cooldown ƒë·ªÉ PIR kh√¥ng k√≠ch l·∫°i ngay
        time.sleep(8)
        st.session_state.cooldown_until = time.time() + 5  # ch·ªù PIR h·∫° xu·ªëng / ng∆∞·ªùi r·ªùi kh·ªèi v√πng
        
        st.session_state.system_state = "IDLE"
        st.rerun()
    else:
        send_to_screen_fail()
        row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": "Unknown", "Tr·∫°ng th√°i": "Th·∫•t b·∫°i"}
        st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)
        
        # Ngh·ªâ v√†i gi√¢y ƒë·ªÉ ng∆∞·ªùi d√πng ƒë·ªçc th√¥ng b√°o / OLED k·ªãp hi·ªÉn th·ªã
        time.sleep(8)
        st.session_state.cooldown_until = time.time() + 2
        st.session_state.system_state = "FAIL_OPT"
        st.rerun()

elif st.session_state.system_state == "FAIL_OPT":
    status_ph.error("‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c!")
    cam_ph.info("B·∫°n c√≥ mu·ªën ƒëƒÉng k√Ω khu√¥n m·∫∑t m·ªõi kh√¥ng?")
    
    with control_container:
        c1, c2 = st.columns(2)
        if c1.button("üìù ƒêƒÉng k√Ω ngay"):
            st.session_state.system_state = "REGISTER"
            st.session_state.reg_step = 1
            st.rerun()
        if c2.button("‚û°Ô∏è B·ªè qua"):
            st.session_state.system_state = "IDLE"
            st.rerun()

elif st.session_state.system_state == "REGISTER":
    if not st.session_state.temp_reg_name:
        cam_ph.empty()
        status_ph.info("Nh·∫≠p t√™n nh√¢n vi√™n m·ªõi:")
        with control_container:
            val = st.text_input("H·ªç v√† T√™n (Vi·∫øt li·ªÅn, kh√¥ng d·∫•u):")
            if st.button("üì∏ B·∫Øt ƒë·∫ßu ch·ª•p") and val:
                st.session_state.temp_reg_name = val
                st.rerun()
    else:
        name = st.session_state.temp_reg_name
        step = st.session_state.reg_step
        msgs = {
            1: "üì∏ B∆Ø·ªöC 1: Nhin thang vao Camera",
            2: "‚¨ÖÔ∏è B∆Ø·ªöC 2: Quay mat sang TRAI (Khoang 30-45 ƒëo)",
            3: "‚û°Ô∏è B∆Ø·ªöC 3: Quay mat sang PHAI (Khoang 30-45 ƒëo)"
        }
        status_ph.markdown(f"### {msgs[step]}")
        ok, frame = auto_capture_stream(cam_ph, status_ph, step, name, face_app)
        
        if ok and frame is not None:
            suffix = ["front", "left", "right"][step-1]
            cv2.imwrite(os.path.join(DATASET_DIR, f"{name}_{suffix}.jpg"), frame)
            st.toast(f"‚úÖ ƒê√£ l∆∞u g√≥c {suffix}!", icon="üíæ")
            
            if step < 3:
                st.session_state.reg_step += 1
                st.rerun()
            else:
                reload_data(face_app)
                st.success("üéâ ƒêƒÉng k√Ω th√†nh c√¥ng!")
                
                row = {"Th·ªùi gian": datetime.now().strftime("%H:%M:%S"), "H·ªç t√™n": name, "Tr·∫°ng th√°i": "ƒêƒÉng k√Ω m·ªõi"}
                st.session_state.attendance_log = pd.concat([pd.DataFrame([row]), st.session_state.attendance_log], ignore_index=True)

                st.session_state.temp_reg_name = ""
                st.session_state.reg_step = 0
                st.session_state.system_state = "IDLE"
                time.sleep(3)
                st.rerun()